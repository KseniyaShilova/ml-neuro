{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c30ba64-a461-4c53-8ba7-9714e8528344",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, precision_score, recall_score\n",
    "#from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "import nltk\n",
    "from nltk import wordpunct_tokenize, WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import gensim.downloader as api\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "116f54d7-1f14-462c-875b-1ae25a227667",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
       "2  user I'd be afraid to short AMZN - they are lo...          1\n",
       "3                                  MNTA Over 12.00            1\n",
       "4                                   OI  Over 21.37            1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Desktop\\stock_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39a3ef1a-d80b-4f12-9e86-c6deefc3ece3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5791, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d461ab3-8049-4ce5-9c7b-19d6e5a5651d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5791 entries, 0 to 5790\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Text       5791 non-null   object\n",
      " 1   Sentiment  5791 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 90.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acea08e1-a546-4946-aada-ffe5466571be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df[\"Text\"].sample().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8491885f-17f9-4aae-b08c-9f53e23ed3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd786c7a-d0e5-4e96-878e-516d44aa6846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4201</th>\n",
       "      <td>ove GNW!! 9-13 Calls are making me feel better...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>CSN option trader buys 1,500 of the Jan 11-16 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4385</th>\n",
       "      <td>people slag AAP for cannibalization but samsun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5773</th>\n",
       "      <td>Sensex opens 166 points lower at 35,469, Nifty...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>CSOD Conf Call: CEO: feeling good about our po...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Sentiment\n",
       "4201  ove GNW!! 9-13 Calls are making me feel better...          1\n",
       "387   CSN option trader buys 1,500 of the Jan 11-16 ...          1\n",
       "4385  people slag AAP for cannibalization but samsun...          1\n",
       "5773  Sensex opens 166 points lower at 35,469, Nifty...         -1\n",
       "2348  CSOD Conf Call: CEO: feeling good about our po...          1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7ff0f52-f884-4d96-a720-09d145598fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>MCP take-over chatter... (I know don't laugh...)</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>AMZN 1,200 lot bid in the Feb weekly 255P. 27 ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>KO made with sugar is sold at local COST. Cons...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523</th>\n",
       "      <td>HNZ Another American Institution sold to forei...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Will watch the close carefully then decide whe...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Sentiment\n",
       "1891   MCP take-over chatter... (I know don't laugh...)         -1\n",
       "1550  AMZN 1,200 lot bid in the Feb weekly 255P. 27 ...         -1\n",
       "1049  KO made with sugar is sold at local COST. Cons...          1\n",
       "2523  HNZ Another American Institution sold to forei...         -1\n",
       "156   Will watch the close carefully then decide whe...         -1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccdd7aed-a359-4fc1-9dcf-648a42d3cef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = SnowballStemmer(\"english\")\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79bedd9c-086a-419c-be32-8d63848748b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stem.stem(\"Earnings\")\n",
    "#lemma.lemmatize(\"Earnings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9fcbdd0-c012-464b-8d02-9c7cfb036259",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ae63f67-515b-48ad-8718-fb37045e3656",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words.remove(\"not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "700b9358-8e46-453e-a69e-029f1f2ff0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.remove(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64f3b64e-14c6-4c37-9ffc-05e1088a6300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # приводим текст к нижнему регистру\n",
    "    text = text.lower()\n",
    "    # создаем регулярное выражение для удаления лишних символов\n",
    "    regular = r'[\\*+\\#+\\№\\\"\\-+\\+\\=+\\?+\\&\\^\\.+\\;\\,+\\>+\\(\\)\\@\\/+\\:\\\\+]'\n",
    "    # регулярное выражение для замены ссылки на \"URL\"\n",
    "    regular_url = r'(http\\S+)|(www\\S+)|([\\w\\d]+www\\S+)|([\\w\\d]+http\\S+)'\n",
    "    # удаляем лишние символы\n",
    "    text = re.sub(regular, '', text)\n",
    "    # заменяем ссылки на \"URL\"\n",
    "    text = re.sub(regular_url, r'URL', text)\n",
    "    # заменяем числа и цифры на ' NUM '\n",
    "    text = re.sub(r'(\\d+\\s\\d+)|(\\d+)',' NUM ', text)\n",
    "    # удаляем лишние пробелы\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # возвращаем очищенные данные\n",
    "    return text\n",
    "    \n",
    "#stop_words.extend(['cannot', 'could', 'done', 'let', 'may' 'mayn',  'might',  'must', 'need', 'ought', 'oughtn', \n",
    "                       #'shall', 'would', 'br'])\n",
    "# создаем список для хранения очищенных данных\n",
    "cleaned_text = []\n",
    "# для каждого сообщения text из столбца data['Message']\n",
    "for text in df['Text']:\n",
    "    # очищаем данные  \n",
    "    text = clean_text(text)\n",
    "    # добавляем очищенные данные в список cleaned_text\n",
    "    cleaned_text.append(text)\n",
    "# записываем очищенные данные в новую колонку 'Cleaned_msg'\n",
    "#df['Cleaned_msg'] = cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a419f33-76fc-4fba-964f-5743589b3d15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf299ed-17e8-4a7c-8bc6-8e6bfb708dae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2d75d33-f6ab-4c25-8841-5983bcf33ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(train_df[\"Text\"].sample(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4b2da75-ff75-4bdd-89f7-d59d63a95e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Text_proceed\"] = train_df[\"Text\"].apply(clean_text)\n",
    "test_df[\"Text_proceed\"] = test_df[\"Text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41c22c20-1e7e-430d-9d47-33f57cee09b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4201    ove gnw!! NUM calls are making me feel better ...\n",
       "387     csn option trader buys NUM of the jan NUM call...\n",
       "4385    people slag aap for cannibalization but samsun...\n",
       "5773    sensex opens NUM points lower at NUM nifty sta...\n",
       "2348    csod conf call ceo feeling good about our posi...\n",
       "                              ...                        \n",
       "3772    aap we break and close below this support NUM ...\n",
       "5191    new industry data provide the first hard look ...\n",
       "5226    rt jchengwsj in hindsight wall street probably...\n",
       "5390    global stocks fall after president trump issue...\n",
       "860     hpq how many upgrades tomorrow assuming autono...\n",
       "Name: Text_proceed, Length: 4632, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Text_proceed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51beff7e-b004-4053-80d8-facef77633a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS_TO_FIT = \"Text_proceed\"\n",
    "TARGET_COL = \"Sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e42e950-506c-4a06-ad51-a96821f11fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecModel(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def get_mean_vector(self, text):\n",
    "        v = np.zeros(300)\n",
    "        c = 0\n",
    "        for word in text.split(\" \"):\n",
    "            if word in self.model:\n",
    "                v += self.model.get_vector(word)\n",
    "                c += 1\n",
    "        c = max(43, c)\n",
    "        return v / c\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([self.get_mean_vector(x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a0001e-b568-4d32-8e73-fcef8d84d1da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8719718d-e189-41b6-92a0-c40d60f3c9de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a8eabe6-3c29-4969-8d86-fb54d28a1a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(ngram_range=(1, 1), min_df = 18, max_df=0.1)),\n",
    "    (\"model\", LogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77c358a5-e970-4d3c-a06a-81ffc65b7ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_df, test_df):\n",
    "    model.fit(train_df[COLS_TO_FIT], train_df[TARGET_COL])\n",
    "    pr = model.predict(test_df[COLS_TO_FIT])\n",
    "    mse = mean_squared_error(test_df[TARGET_COL], pr)\n",
    "    out = accuracy_score(test_df[TARGET_COL], pr)\n",
    "    print(f\"mse: {mean_squared_error(test_df[TARGET_COL], pr):.3f}\")\n",
    "    print(f\"mae: {mean_absolute_error(test_df[TARGET_COL], pr):.3f}\")\n",
    "    print(f\"out: {accuracy_score(test_df[TARGET_COL], pr):.3f}\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "246da552-fca3-4f05-8ef5-280301d09f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.966\n",
      "mae: 0.483\n",
      "out: 0.758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7584124245038827"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_validate(pipe, train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6697e054-eada-4580-86d8-39f31682580b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6821f091-738f-412c-994c-caa9a2ad1da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer()),\n",
    "    (\"model\", LogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a633000-793b-435b-a55b-4e18c1f54783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.808\n",
      "mae: 0.404\n",
      "out: 0.798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\miniconda3\\envs\\mlisuct\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7981018119068162"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_validate(pipe, train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b0a056-503a-44d3-a76d-e749a1e9e0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de5f88e9-d4e1-4105-a6ed-5383e4bae138",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc0a693-fde4-48a5-b852-f3fa1907ff01",
   "metadata": {},
   "source": [
    "# Лучший результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2314060-e0d4-4f44-9faa-7d59d22eaac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(ngram_range=(1, 9), min_df = 1, max_df=0.1)),\n",
    "    (\"model\", LogisticRegression(C=1, penalty=\"l1\", solver=\"saga\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9feaf999-5e72-4766-bb3a-2486026a35d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\miniconda3\\envs\\mlisuct\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.777\n",
      "mae: 0.388\n",
      "out: 0.806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8058671268334772"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_validate(pipe, train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab693e1-d0de-4a1a-8fff-505da9533747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21a58da-606a-4741-8b13-b9e0a8a26afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(token_pattern=r\"\\S+\", ngram_range=(1, 1), min_df = 5, max_df=0.9)),\n",
    "    (\"model\", LogisticRegression(C=2, penalty=\"l2\", solver=\"saga\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14bd1e2-ae3f-4df7-8fa6-ed24af05cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(pipe, train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92559902-90a8-49b6-8a7d-0c644b028f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ff7ff-a671-4139-b49a-5c4e3caaef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(ngram_range=(1, 9), min_df = 5, max_df=0.1)),\n",
    "    (\"model\", LogisticRegression(C=2, penalty=\"elasticnet\", solver=\"saga\", l1_ratio=1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7486be-869a-49db-a857-2ca6f3f8badf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(pipe, train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bb334c-9ea9-4636-915d-0e9f315b153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer()),\n",
    "    (\"model\", LogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99486c43-6a9f-4070-a0f0-6624640d175b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03ea6f5-199f-4f36-9cf2-725537e5a742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34890d7a-50d1-43f0-ac84-0ae16909f0ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "parameters = {\n",
    "    'model__penalty': [\"l1\"],\n",
    "    'vectorizer__ngram_range': [(1,9)],\n",
    "   # 'vectorizer__max_df': np.arange(0.1, 0.9, 0.1),\n",
    "    #'vectorizer__min_df': np.arange(1, 10, 1),\n",
    "    #'model__l1_ratio' : [0.1],\n",
    "    'model__solver': [\"saga\"],\n",
    "    'model__C': np.arange(2.5, 3, 0.1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e1b12b-6152-4b47-8f30-bc30bb67a121",
   "metadata": {
    "tags": []
   },
   "source": [
    "cv = GridSearchCV(estimator=pipe, param_grid=parameters, cv=KFold(5, shuffle=True), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e11d891-08cd-419d-8d49-6db8e9160e15",
   "metadata": {
    "tags": []
   },
   "source": [
    "cv.fit(train_df[COLS_TO_FIT], train_df[TARGET_COL])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74974b04-4d1c-4944-866d-2d8a53522be2",
   "metadata": {
    "tags": []
   },
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb9affd-e5c3-480f-b98a-8c5fb62a0ccf",
   "metadata": {
    "tags": []
   },
   "source": [
    "cv.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5050ea62-7074-4a26-91e6-041a919e8b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_estimator_.named_steps[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e4ee74-bd4c-42da-8f6e-6a3dd290ee5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223162f7-67aa-4b2c-938c-5e8130f8c999",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'model__penalty': [\"l1\"],\n",
    "    'vectorizer__ngram_range': [(1,9)],\n",
    "    'vectorizer__max_df': [(0.1)],\n",
    "    'vectorizer__min_df': np.arange(1, 2, 1),\n",
    "    #'model__l1_ratio' : [0.1],\n",
    "    'model__solver': [\"saga\"],\n",
    "    'model__C': np.arange(1, 2.5, 1.5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719c8cc3-4386-4052-9b0b-871f16f2c376",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = GridSearchCV(estimator=pipe, param_grid=parameters, cv=KFold(5, shuffle=True), n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a8b9b7-0194-44b7-ae7b-40e584a54395",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(train_df[COLS_TO_FIT], train_df[TARGET_COL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650ef5da-029b-40e6-860a-b42279dd96c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d67bec4-cb94-4f21-8e8c-eb69a5a6015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6afb73-70ce-4e29-b9ad-6e374a5fa831",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_estimator_.named_steps[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1375ab63-9f65-4d73-824c-5d35125d9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cdb16a-b2a2-4fbb-8c37-a6a437909b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer()),\n",
    "    (\"model\", LogisticRegression(solver=\"saga\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb653af3-a8a5-4007-9c3e-6d213a659f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(pipe, train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022c0cf9-c5a9-47f5-ab6c-b9baf493f292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2e4c9ae-0fb1-43d9-83c7-2148817c6b8c",
   "metadata": {},
   "source": [
    "   def preprocessing(token):\n",
    "    # Copied from here\n",
    "    token = re.sub(r\"(...)our$\", r\"\\1or\", token)\n",
    "    token = re.sub(r\"([bt])re$\", r\"\\1er\", token)\n",
    "    token = re.sub(r\"([iy])s(e$|ing|ation)\", r\"\\1z\\2\", token)\n",
    "    token = re.sub(r\"ogue$\", \"og\", token)\n",
    "    return token\n",
    "def correct_typo(tokens):\n",
    "    spell = SpellChecker()\n",
    "    return [spell.correction(t) if len(spell.unknown([t]))>0 else t for t in tokens]\n",
    "        \n",
    "def preprocess_text(text):\n",
    "    # 1. Tokenise to alphabetic tokens\n",
    "    tokeniser = RegexpTokenizer(r'[A-Za-z]+')\n",
    "    tokens = tokeniser.tokenize(text)\n",
    "    \n",
    "    # 2. Lowercase and lemmatise\n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    tokens = [lemmatiser.lemmatize(t.lower(), pos='v') for t in tokens]\n",
    "# 3. Correct spelling (this won't convert 100% )\n",
    "    tokens = correct_typo(tokens)\n",
    "    \n",
    "    # 4. Convert British spelling to American spelling (this won't convert 100%)\n",
    "    tokens = [convert_to_american(t) for t in tokens]\n",
    "# 5. Remove stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words.extend(['cannot', 'could', 'done', 'let', 'may' 'mayn',  'might',  'must', 'need', 'ought', 'oughtn', \n",
    "                       'shall', 'would', 'br'])\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    \n",
    "    return tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
