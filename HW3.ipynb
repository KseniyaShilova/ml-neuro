{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c30ba64-a461-4c53-8ba7-9714e8528344",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression, SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import nltk\n",
    "from nltk import wordpunct_tokenize, WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import gensim.downloader as api\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "116f54d7-1f14-462c-875b-1ae25a227667",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
       "2  user I'd be afraid to short AMZN - they are lo...          1\n",
       "3                                  MNTA Over 12.00            1\n",
       "4                                   OI  Over 21.37            1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Desktop\\stock_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39a3ef1a-d80b-4f12-9e86-c6deefc3ece3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5791, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d461ab3-8049-4ce5-9c7b-19d6e5a5651d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5791 entries, 0 to 5790\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Text       5791 non-null   object\n",
      " 1   Sentiment  5791 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 90.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a74658-93e8-4b76-bc9e-82a46c42d96c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8054645b-261f-4227-af7e-aaa33912e70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(df.shape[0] * 0.8)\n",
    "train_df = df.iloc[:train_size].copy()\n",
    "test_df = df.iloc[train_size:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f64927c8-6ad0-46d8-b2c0-7091ebc916cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4632, 2), (1159, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da116a7f-43c2-444c-b9de-075f49fa8189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['track name'] = df['track name'].str.replace(r'\\W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bcc6f7c-e630-4431-b3a0-a525d815d082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5791.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.272664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.962192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sentiment\n",
       "count  5791.000000\n",
       "mean      0.272664\n",
       "std       0.962192\n",
       "min      -1.000000\n",
       "25%      -1.000000\n",
       "50%       1.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af51b080-d6a3-46dc-ad17-edf1301a592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5ca9dd0-0c7f-4b03-b486-c50d11c6c912",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sns.countplot(x='Sentiment',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acea08e1-a546-4946-aada-ffe5466571be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VXY Da bears wacked again? gap fill from yesterday. 10 on AAP 15% rev beat?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Text\"].sample().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fa31a8f-9994-432b-ad4e-3b1ee2df42d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = SnowballStemmer(\"english\")\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca854931-800c-4142-8ae2-9bf939f92397",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_english = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19b6895a-41b7-460b-8d51-b9fae72f2338",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_english = set(stopwords_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "777ea9d0-ddf7-436d-8651-70b9b6761e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_english.remove(\"not\")\n",
    "#stopwords_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66815e4b-4df4-4a4f-acfa-1ceceaec6bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_ALPHA = re.compile(\"[\\w!?]+\")\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.replace(\"&\", \" and \")\n",
    "    text = text.replace(\"n't\", \" not \")\n",
    "    text = text.lower()\n",
    "    text_tokens = wordpunct_tokenize(text)\n",
    "    text_tokens = [lemma.lemmatize(token) for token in text_tokens if IS_ALPHA.match(token)]\n",
    "    text_tokens = [token for token in text_tokens if token not in stopwords_english]\n",
    "    text = \" \".join(text_tokens)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38704519-aaf4-45f2-9fd5-7e96937b1d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Text_proceed\"] = train_df[\"Text\"].apply(preprocess)\n",
    "test_df[\"Text_proceed\"] = test_df[\"Text\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b58e4d4-5bf5-430e-9442-ec1cdf537ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       kicker watchlist xide tit soq pnk cpw bpz aj t...\n",
       "1       user aap movie 55 return fea geed indicator 15...\n",
       "2       user afraid short amzn looking like near monop...\n",
       "3                                              mnta 12 00\n",
       "4                                                oi 21 37\n",
       "                              ...                        \n",
       "4627                                    idti like 7 41 42\n",
       "4628                acad trying go higher need followthru\n",
       "4629                                   get back !!! silly\n",
       "4630    today watchlist ong stock jaso ziop vhc snfca ...\n",
       "4631                           aap kumo earjet kumo twist\n",
       "Name: Text_proceed, Length: 4632, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Text_proceed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94c5b956-cb4c-44a5-913e-7d4c76608638",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS_TO_FIT = \"Text_proceed\"\n",
    "TARGET_COL = \"Sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c187460c-d7b7-4b4c-a739-2223e0880a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6273451b-7027-49f2-ab91-6d830725dbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(token_pattern=r\"\\S+\")),\n",
    "    (\"model\", LogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73aa5960-e704-4b25-af33-602839a04e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_df, test_df):\n",
    "    model.fit(train_df[COLS_TO_FIT], train_df[TARGET_COL])\n",
    "    prediction = model.predict(test_df[COLS_TO_FIT])\n",
    "    mse = mean_squared_error(test_df[TARGET_COL], prediction)\n",
    "    print(f\"mse: {mean_squared_error(test_df[TARGET_COL], prediction):.3f}\")\n",
    "    print(f\"mae: {mean_absolute_error(test_df[TARGET_COL], prediction):.3f}\")\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fcdde51-b70e-4eff-89e0-91358d8a38a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 1.726\n",
      "mae: 0.863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.7256255392579811"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_validate(pipe, train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1beea2-fa74-428d-8225-c17750884bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(token_pattern=r\"\\S+\", ngram_range=(1, 2))),\n",
    "    (\"model\", LogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5760f9c7-7736-43de-961f-4942868c24bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 1.808\n",
      "mae: 0.904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.8084555651423642"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_validate(pipe, train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab79d71c-4270-41d5-a1b6-52b4deac4eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(token_pattern=r\"\\S+\", ngram_range=(1, 1), min_df=5, max_df=0.3)),\n",
    "    (\"model\", LogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5c7144d-6e69-43da-8a59-5b0c42ab432c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 1.670\n",
      "mae: 0.835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.6704055220017255"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_validate(pipe, train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d06e0772-0ed7-4daa-8808-1a7247e6dc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 1.833\n",
      "mae: 0.916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.8326143226919758"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer(token_pattern=r\"\\S+\", ngram_range=(1, 1), min_df=5, max_df=0.3)),\n",
    "    (\"model\", LogisticRegression()),\n",
    "])\n",
    "train_and_validate(pipe, train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d55a82c0-7d0f-4fc2-a68b-4528bf9ed25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe4ff94f-deda-4884-899f-805685c691a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecModel(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def get_mean_vector(self, text):\n",
    "        v = np.zeros(300)\n",
    "        c = 0\n",
    "        for word in text.split(\" \"):\n",
    "            if word in self.model:\n",
    "                v += self.model.get_vector(word)\n",
    "                c += 1\n",
    "        c = max(1, c)\n",
    "        return v / c\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([self.get_mean_vector(x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e34e9137-2937-4cc6-a07b-e46a8c93ced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", Word2VecModel(model)),\n",
    "    (\"model\",  LogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f16d0b7c-2f25-47ea-8f4a-73cbafd84b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 1.805\n",
      "mae: 0.903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.805004314063848"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_validate(pipe, train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7fad5701-2934-4e52-ad4f-cc2c4c1b1b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.scatterplot(x=train_df[\"Text\"], y=train_df[\"Sentiment\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bfdb17-61f2-4706-863a-61643cc9e367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9efc7e-8f7d-4a74-8c19-519597df5bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "BRACETS_RE = re.compile(r\"\\[[^\\]]*\\]\")\n",
    "PUNK_RE= re.compile(r\"[.,\\\"'#@%:;$* \\t\\n^/\\\\-]+\")\n",
    "\n",
    "def preprocessing(text):\n",
    "    text = BRACETS_RE.sub(\"\", text)\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"&\", \" and \")\n",
    "    text = text.replace(\"n't\", \" not \")\n",
    "    text = text.replace(\"n'\", \" not \")\n",
    "    text = PUNK_RE.sub(\" \", text)\n",
    "\n",
    "    text_list = wordpunct_tokenize(text)\n",
    "    text_list = [lemma.lemmatize(word) for word in text_list if word not in stop_words]\n",
    "    ##text_list.extend([\"_\".join(text_list[i:i+2]) for i in range(len(text_list)-1)])\n",
    "    ##text_list = [token for token in text_list if token not in stop_english]\n",
    "    text = \" \".join(text_list)\n",
    "    \n",
    "    return text.strip()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
