{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81e344e0-b6b7-468a-99df-4c98cfcf2d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression, SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score\n",
    "import nltk\n",
    "from nltk import wordpunct_tokenize, WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import gensim.downloader as api\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f170fb6d-99b0-4710-91dd-5003ce322e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
       "2  user I'd be afraid to short AMZN - they are lo...          1\n",
       "3                                  MNTA Over 12.00            1\n",
       "4                                   OI  Over 21.37            1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Desktop\\stock_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "749f1320-6a28-4937-b507-69622ef53083",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c67f8527-4274-4566-9423-ea52ce3bbdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = SnowballStemmer(\"english\")\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2eb7be5-cce8-479f-8ef7-6e6857b81a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_english = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64a1f581-6695-4432-a66e-8473d3ad4896",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_english = set(stopwords_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63412941-f710-4656-a7d3-0bdc745991b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_english.remove(\"not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "845b3a2e-b5b3-4626-8de1-22777372fd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_ALPHA = re.compile(\"[\\w!?]+\")\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.replace(\"&\", \" and \")\n",
    "    text = text.replace(\"n't\", \" not \")\n",
    "    text = text.lower()\n",
    "    text_tokens = wordpunct_tokenize(text)\n",
    "    text_tokens = [lemma.lemmatize(token) for token in text_tokens if IS_ALPHA.match(token)]\n",
    "    text_tokens = [token for token in text_tokens if token not in stopwords_english]\n",
    "    text = \" \".join(text_tokens)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79b83c9a-ae4f-4f98-b07d-2a3e670e1d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Text_proceed\"] = train_df[\"Text\"].apply(preprocess)\n",
    "test_df[\"Text_proceed\"] = test_df[\"Text\"].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b59301d-b2c7-4e03-92db-a41f4fa54839",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS_TO_FIT = \"Text\"\n",
    "TARGET_COL = \"Sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ea5dac3-73e7-4e24-ad37-cd2526fdcb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecModel(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def get_mean_vector(self, text):\n",
    "        v = np.zeros(300)\n",
    "        c = 0\n",
    "        for word in text.split(\" \"):\n",
    "            if word in self.model:\n",
    "                v += self.model.get_vector(word)\n",
    "                c += 1\n",
    "        c = max(43, c)\n",
    "        return v / c\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([self.get_mean_vector(x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "715d4369-44d3-48a1-93d7-25666a2f2d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "369fbaf4-2012-4a99-8111-fae6a633ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c65850f0-e871-4eb0-8c36-ae7c137fc7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_df, test_df):\n",
    "    model.fit(train_df[COLS_TO_FIT], train_df[TARGET_COL])\n",
    "    prod = model.predict(test_df[COLS_TO_FIT])\n",
    "    acc = accuracy_score(test_df[TARGET_COL], prod)\n",
    "    print(f\"acc: {accuracy_score(test_df[TARGET_COL], prod):.3f}\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3bf43b3-f551-4cd0-99e7-c596cc35b609",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(ngram_range=(1, 4))),\n",
    "    (\"model\", LogisticRegression(C=4.27, penalty=\"l1\", solver=\"saga\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e0a7416-ee29-4ab0-9bfe-338779402ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\miniconda3\\envs\\mlisuct\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.811044003451251"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_validate(pipe, train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cd2a0b6-5cdd-4dc9-9b20-2b877d7db37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(ngram_range=(1, 2))),\n",
    "    (\"model\", LogisticRegression(C=2.27, penalty=\"l1\", solver=\"saga\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d952ce7e-20c0-4f76-8836-bc2379fe6fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\miniconda3\\envs\\mlisuct\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8058671268334772"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_validate(pipe, train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aed6576b-ecea-4ab3-b5d1-7f07446efdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(ngram_range=(1, 3))),\n",
    "    (\"model\", LogisticRegression(C=3.27, penalty=\"l1\", solver=\"saga\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dedac275-4fb9-473b-b5c8-d8f0da7bbf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\miniconda3\\envs\\mlisuct\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.808455565142364"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_validate(pipe, train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d3a18b6-bfff-4ff2-9b4d-594d86c5361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(ngram_range=(1, 2))),\n",
    "    (\"model\", LogisticRegression(C=2.27, penalty=\"l2\", solver=\"saga\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96cd55f8-b8e3-4445-9a3e-6a3c5d56efe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\miniconda3\\envs\\mlisuct\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8015530629853321"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_validate(pipe, train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02168d44-707d-45b3-8500-c6afb5ce9644",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(ngram_range=(1, 2))),\n",
    "    (\"model\", LogisticRegression(C=2, penalty=\"elasticnet\", solver=\"saga\", l1_ratio=1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa6b5ca3-615e-4d0e-8377-7516ae900455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\miniconda3\\envs\\mlisuct\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8093183779119931"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_validate(pipe, train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9327b989-c027-4c52-81ab-2793c49d64c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
