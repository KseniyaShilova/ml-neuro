{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c30ba64-a461-4c53-8ba7-9714e8528344",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "import nltk\n",
    "from nltk import wordpunct_tokenize, WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "import gensim.downloader as api\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import re\n",
    "import string\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "116f54d7-1f14-462c-875b-1ae25a227667",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
       "2  user I'd be afraid to short AMZN - they are lo...          1\n",
       "3                                  MNTA Over 12.00            1\n",
       "4                                   OI  Over 21.37            1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Desktop\\stock_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8491885f-17f9-4aae-b08c-9f53e23ed3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd786c7a-d0e5-4e96-878e-516d44aa6846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4201</th>\n",
       "      <td>ove GNW!! 9-13 Calls are making me feel better...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>CSN option trader buys 1,500 of the Jan 11-16 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4385</th>\n",
       "      <td>people slag AAP for cannibalization but samsun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5773</th>\n",
       "      <td>Sensex opens 166 points lower at 35,469, Nifty...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>CSOD Conf Call: CEO: feeling good about our po...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Sentiment\n",
       "4201  ove GNW!! 9-13 Calls are making me feel better...          1\n",
       "387   CSN option trader buys 1,500 of the Jan 11-16 ...          1\n",
       "4385  people slag AAP for cannibalization but samsun...          1\n",
       "5773  Sensex opens 166 points lower at 35,469, Nifty...         -1\n",
       "2348  CSOD Conf Call: CEO: feeling good about our po...          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fba4666-b5e3-4a1b-974d-fd458543590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stem = SnowballStemmer(\"english\")\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ccb0a09-e905-475e-b653-0098e7ab67dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_english = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "829b4944-0ff1-4cf2-82fe-b15d25909502",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_english = set(stopwords_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98f1f2a4-146b-4577-b616-6972b59d2a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_english.remove(\"not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2cae1d3-5cec-4501-8561-9fb40d77c20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_english.remove(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89d0e39f-bcbb-4a53-a96e-21dee32f31f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # приводим текст к нижнему регистру\n",
    "    text = text.lower()\n",
    "    # создаем регулярное выражение для удаления лишних символов\n",
    "    regular = r'[\\*+\\#+\\№\\\"\\-+\\+\\=+\\?+\\&\\^\\.+\\;\\,+\\>+\\(\\)\\/+\\:\\\\+]'\n",
    "    # регулярное выражение для замены ссылки на \"URL\"\n",
    "    regular_url = r'(http\\S+)|(www\\S+)|([\\w\\d]+www\\S+)|([\\w\\d]+http\\S+)'\n",
    "    # удаляем лишние символы\n",
    "    text = re.sub(regular, '', text)\n",
    "    # заменяем ссылки на \"URL\"\n",
    "    text = re.sub(regular_url, r'URL', text)\n",
    "    # заменяем числа и цифры на ' NUM '\n",
    "    text = re.sub(r'(\\d+\\s\\d+)|(\\d+)',' NUM ', text)\n",
    "    # удаляем лишние пробелы\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # возвращаем очищенные данные\n",
    "    return text\n",
    " \n",
    "# создаем список для хранения очищенных данных\n",
    "cleaned_text = []\n",
    "# для каждого сообщения text из столбца data['Message']\n",
    "for text in df['Text']:\n",
    "    # очищаем данные  \n",
    "    text = clean_text(text)\n",
    "    # добавляем очищенные данные в список cleaned_text\n",
    "    cleaned_text.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd442fc9-ab6c-4720-a57a-8cb6103f84cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1891     MCP take-over chatter... (I know don't laugh...)\n",
       "1550    AMZN 1,200 lot bid in the Feb weekly 255P. 27 ...\n",
       "1049    KO made with sugar is sold at local COST. Cons...\n",
       "2523    HNZ Another American Institution sold to forei...\n",
       "156     Will watch the close carefully then decide whe...\n",
       "                              ...                        \n",
       "5684    Sensex jumps over 750 points to cross 29,000 m...\n",
       "3090                      VBD may be about move back up  \n",
       "203     CSX enko view, PF Box size = 1,  VEY bullish a...\n",
       "339           AYI Q1 Operational Cash Flow turns Negative\n",
       "837     user: NFX ising wedge. Normally bearish. Close...\n",
       "Name: Text, Length: 1159, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d978383a-c760-466f-98b4-1f9e69d17f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdecea08-0850-4d29-b244-786baa1f5bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Text_proceed\"] = train_df[\"Text\"].apply(clean_text)\n",
    "test_df[\"Text_proceed\"] = test_df[\"Text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "517d4b7a-b2b8-44d2-9c5c-e1675d316e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4201    ove gnw!! NUM calls are making me feel better ...\n",
       "387     csn option trader buys NUM of the jan NUM call...\n",
       "4385    people slag aap for cannibalization but samsun...\n",
       "5773    sensex opens NUM points lower at NUM nifty sta...\n",
       "2348    csod conf call ceo feeling good about our posi...\n",
       "                              ...                        \n",
       "3772    aap we break and close below this support NUM ...\n",
       "5191    new industry data provide the first hard look ...\n",
       "5226    rt @jchengwsj in hindsight wall street probabl...\n",
       "5390    global stocks fall after president trump issue...\n",
       "860     hpq how many upgrades tomorrow assuming autono...\n",
       "Name: Text_proceed, Length: 4632, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Text_proceed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51beff7e-b004-4053-80d8-facef77633a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS_TO_FIT = \"Text_proceed\"\n",
    "TARGET_COL = \"Sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e42e950-506c-4a06-ad51-a96821f11fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecModel(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def get_mean_vector(self, text):\n",
    "        v = np.zeros(300)\n",
    "        c = 0\n",
    "        for word in text.split(\" \"):\n",
    "            if word in self.model:\n",
    "                v += self.model.get_vector(word)\n",
    "                c += 1\n",
    "        c = max(43, c)\n",
    "        return v / c\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([self.get_mean_vector(x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59a0001e-b568-4d32-8e73-fcef8d84d1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text_proceed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>MCP take-over chatter... (I know don't laugh...)</td>\n",
       "      <td>-1</td>\n",
       "      <td>mcp takeover chatter i know don't laugh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>AMZN 1,200 lot bid in the Feb weekly 255P. 27 ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>amzn NUM lot bid in the feb weekly NUM p NUM d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>KO made with sugar is sold at local COST. Cons...</td>\n",
       "      <td>1</td>\n",
       "      <td>ko made with sugar is sold at local cost consu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523</th>\n",
       "      <td>HNZ Another American Institution sold to forei...</td>\n",
       "      <td>-1</td>\n",
       "      <td>hnz another american institution sold to forei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Will watch the close carefully then decide whe...</td>\n",
       "      <td>-1</td>\n",
       "      <td>will watch the close carefully then decide whe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Sentiment  \\\n",
       "1891   MCP take-over chatter... (I know don't laugh...)         -1   \n",
       "1550  AMZN 1,200 lot bid in the Feb weekly 255P. 27 ...         -1   \n",
       "1049  KO made with sugar is sold at local COST. Cons...          1   \n",
       "2523  HNZ Another American Institution sold to forei...         -1   \n",
       "156   Will watch the close carefully then decide whe...         -1   \n",
       "\n",
       "                                           Text_proceed  \n",
       "1891            mcp takeover chatter i know don't laugh  \n",
       "1550  amzn NUM lot bid in the feb weekly NUM p NUM d...  \n",
       "1049  ko made with sugar is sold at local cost consu...  \n",
       "2523  hnz another american institution sold to forei...  \n",
       "156   will watch the close carefully then decide whe...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8719718d-e189-41b6-92a0-c40d60f3c9de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6697e054-eada-4580-86d8-39f31682580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77c358a5-e970-4d3c-a06a-81ffc65b7ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(model, train_df, test_df):\n",
    "    model.fit(train_df[COLS_TO_FIT], train_df[TARGET_COL])\n",
    "    predict = model.predict(test_df[COLS_TO_FIT])\n",
    "    proc = accuracy_score(test_df[TARGET_COL], predict)\n",
    "    print(f\"proc: {accuracy_score(test_df[TARGET_COL], predict):.3f}\")\n",
    "    return proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7aecf924-6426-4a66-861a-13cbdf3a53ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(ngram_range=(1, 2))),\n",
    "    (\"model\", LogisticRegression(C=10.83, penalty=\"l1\", solver=\"saga\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ee5e014-6256-4ad1-9805-921e54423f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proc: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\miniconda3\\envs\\mlisuct\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8119068162208801"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_validate(pipe, train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de5f88e9-d4e1-4105-a6ed-5383e4bae138",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = api.load(\"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0afd88d-5a72-4371-b3c4-e0716e4d2e53",
   "metadata": {},
   "source": [
    "THE BEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4965899-b88b-4d81-8b56-d20b9d71e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(ngram_range=(1, 2))),\n",
    "    (\"model\", LogisticRegression(C=10.83, penalty=\"l1\", solver=\"saga\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b83c3234-081c-4c44-b719-56879c1dfb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proc: 0.813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\miniconda3\\envs\\mlisuct\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8127696289905091"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_validate(pipe, train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2314060-e0d4-4f44-9faa-7d59d22eaac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(ngram_range=(1, 7), min_df = 1, max_df=0.1)),\n",
    "    (\"model\", LogisticRegression(C=20, penalty=\"l1\", solver=\"saga\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9feaf999-5e72-4766-bb3a-2486026a35d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\miniconda3\\envs\\mlisuct\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proc: 0.799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7989646246764452"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_validate(pipe, train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f21a58da-606a-4741-8b13-b9e0a8a26afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(ngram_range=(1, 3))),\n",
    "    (\"model\", LogisticRegression(C=4.99, penalty=\"l2\", solver=\"saga\")),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f14bd1e2-ae3f-4df7-8fa6-ed24af05cdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proc: 0.804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\miniconda3\\envs\\mlisuct\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8041415012942191"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_validate(pipe, train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d84ff7ff-a671-4139-b49a-5c4e3caaef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"vectorizer\", CountVectorizer(ngram_range=(1, 2))),\n",
    "    (\"model\", LogisticRegression(C=0.82, penalty=\"elasticnet\", solver=\"saga\", l1_ratio=1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a7486be-869a-49db-a857-2ca6f3f8badf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proc: 0.804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\miniconda3\\envs\\mlisuct\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8041415012942191"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_validate(pipe, train_df, test_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
